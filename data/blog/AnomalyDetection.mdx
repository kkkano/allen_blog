---
title: '异常检测：高斯模型在服务器异常检测中的应用'
date: '2025-04-21'
tags: ['Machine Learning', 'Anomaly Detection', 'Gaussian Model', 'Data Science']
draft: false
summary: '本文详细讲解了异常检测算法的原理与实现，从理论基础到实际应用，通过监测服务器指标来检测网络中的异常行为。'
authors: ['allen']
---

在这篇博客中，我们将一起实现异常检测算法，并将其应用于检测网络中的故障服务器。

## 目录

- [1 - 准备工具包](#1)
- [2 - 异常检测](#2)
  - [2.1 问题背景](#2.1)
  - [2.2 数据集概览](#2.2)
  - [2.3 高斯分布模型](#2.3)
    - [练习 1：估计高斯参数](#ex01)
    - [练习 2：选择阈值](#ex02)
  - [2.4 应用于高维数据](#2.4)
- [总结](#summary)

---

<a name="1"></a>
## 1 - 准备工具包

在开始之前，我们需要准备一些 Python 工具包，它们将帮助我们处理数据、进行计算和可视化结果。

- **[NumPy](https://numpy.org/)**：Python 中用于数值运算和矩阵处理的库。
- **[Matplotlib](https://matplotlib.org/)**：一个强大的绘图库，用于生成数据可视化图表。
- **`utils.py`**：一个辅助文件，包含本任务的预置函数（无需修改）。

运行以下代码以加载这些工具：

```python
import numpy as np
import matplotlib.pyplot as plt
from utils import *

%matplotlib inline
```

工具准备好后，我们正式进入异常检测的学习之旅！

---

<a name="2"></a>
## 2 - 异常检测

<a name="2.1"></a>
### 2.1 问题背景

假设你正在管理一个服务器网络，需要及时发现行为异常的服务器——比如故障服务器。在这个任务中，我们将构建一个异常检测算法来识别这些问题。我们的数据集包含两个关键的服务器指标：

- **吞吐量 (mb/s)**：数据传输速率。
- **延迟 (ms)**：响应时间。

我们收集了 307 个服务器行为样本。大多数样本应该是“正常”的，但其中可能有一些异常样本——即故障服务器。我们的目标是使用高斯分布模型来识别这些异常样本。我们将从一个二维数据集开始，以便可视化算法的效果，然后扩展到更复杂的高维数据集。

<a name="2.2"></a>
### 2.2 数据集概览

让我们加载并检查数据集。`load_data()` 函数为我们提供了三个变量：

- **`X_train`**：训练数据，用于拟合高斯模型。
- **`X_val`**：验证数据，用于调整阈值。
- **`y_val`**：验证集的标签（1 = 异常，0 = 正常）。

```python
# 加载数据集
X_train, X_val, y_val = load_data()
```

#### 初步查看数据

让我们打印每个变量的前五个元素，了解数据的结构：

```python
print("X_train 的前五个元素:\n", X_train[:5])
print("X_val 的前五个元素:\n", X_val[:5])
print("y_val 的前五个元素:\n", y_val[:5])
```

**输出：**

```
X_train 的前五个元素:
 [[13.04681517 14.74115241]
 [13.40852019 13.7632696 ]
 [14.19591481 15.85318113]
 [14.91470077 16.17425987]
 [13.57669961 14.04284944]]

X_val 的前五个元素:
 [[15.79025979 14.9210243 ]
 [13.63961877 15.32995521]
 [14.86589943 16.47386514]
 [13.58467605 13.98930611]
 [13.46404167 15.63533011]]

y_val 的前五个元素:
 [0 0 0 0 0]
```

- `X_train` 和 `X_val` 是数组，每行是一个样本，包含两个特征：延迟和吞吐量。
- `y_val` 是标签，指示验证样本是否为异常（1）或正常（0）。

#### 检查数据维度

了解数据的维度有助于我们掌握数据集的规模：

```python
print("X_train 的形状:", X_train.shape)
print("X_val 的形状:", X_val.shape)
print("y_val 的形状:", y_val.shape)
```

**输出：**

```
X_train 的形状: (307, 2)
X_val 的形状: (307, 2)
y_val 的形状: (307,)
```

训练集和验证集各有 307 个样本，每个样本有两个特征。

#### 数据可视化

通过散点图，我们可以直观地看到数据的分布：

```python
# Create a scatter plot of the data. To change the markers to blue "x",
# we used the 'marker' and 'c' parameters
plt.scatter(X_train[:, 0], X_train[:, 1], marker='x', c='b')
plt.title("服务器延迟 vs 吞吐量")
plt.ylabel("吞吐量 (mb/s)")
plt.xlabel("延迟 (ms)")
plt.axis([0, 30, 0, 30])
plt.show()
```

![dataset](/static/images/MLc3/outputw1_13_0.png)
大多数点聚集在一起，但有几个离群点可能就是异常样本。我们的任务是系统地检测它们。

---

<a name="2.3"></a>
### 2.3 高斯分布模型

为了检测异常，我们将使用高斯（正态）分布来建模数据的分布。对于每个特征 \(i\)，我们需要估计：

- **均值 (\(\mu_i\))**: 特征的平均值。
- **方差 (\(\sigma_i^2\))**: 特征的离散程度。

高斯概率密度函数为：

$$p(x ; \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\frac{(x - \mu)^2}{2 \sigma^2} \right)$$

<a name="ex01"></a>

#### 练习 1：估计高斯参数

让我们编写一个函数来计算 `X_train` 中每个特征的 $\mu$ 和 $\sigma^2$：

```python
def estimate_gaussian(X):
    """
    计算数据集每个特征的均值和方差。

    参数:
        X (ndarray): (m, n) 数据矩阵

    返回:
        mu (ndarray): (n,) 每个特征的均值
        var (ndarray): (n,) 每个特征的方差
    """
    m, n = X.shape
    mu = np.mean(X, axis=0)  # 按列计算均值
    var = np.var(X, axis=0)  # 按列计算方差
    return mu, var
```

- `np.mean(X, axis=0)`: 计算每个特征的均值。
- `np.var(X, axis=0)`: 计算每个特征的方差。

测试一下：

```python
mu, var = estimate_gaussian(X_train)
print("每个特征的均值:", mu)
print("每个特征的方差:", var)
```

**输出：**

```
每个特征的均值: [14.11222578 14.99771051]
每个特征的方差: [1.83263141 1.70974533]
```

#### 可视化拟合

使用 `utils.py` 中的 `multivariate_gaussian` 函数计算概率，并绘制高斯拟合图：

```python
# Returns the density of the multivariate normal
# at each data point (row) of X_train
p = multivariate_gaussian(X_train, mu, var)
#Plotting code
visualize_fit(X_train, mu, var)
```

![等高线图1](/static/images/MLc3/outputw1_22_0.png)
等高线显示了概率密度——大多数点位于高概率区域，而异常点则在低概率区域。

<a name="ex02"></a>
#### 练习 2：选择阈值

接下来，我们需要一个阈值 \(\epsilon\) 来判断异常（当 \(p(x) < \epsilon\) 时）。我们将使用验证集 (`X_val`, `y_val`) 和 \(F_1\) 分数来找到最佳的 \(\epsilon\)。

\(F_1\) 分数是精确率和召回率的调和平均：

$$F_1 = \frac{2 \cdot \text{prec} \cdot \text{rec}}{\text{prec} + \text{rec}}$$

其中：

- $\text{prec} = \frac{\text{tp}}{\text{tp} + \text{fp}}$（精确率）
- $\text{rec} = \frac{\text{tp}}{\text{tp} + \text{fn}}$（召回率）
- $\text{tp}$: 真正例（正确识别的异常）
- $\text{fp}$: 假正例（误报为异常）
- $\text{fn}$: 假负例（漏报的异常）

实现如下：

```python
def select_threshold(y_val, p_val):
    """
    寻找最佳阈值 (epsilon) 来检测异常。

    参数:
        y_val (ndarray): 真实标签
        p_val (ndarray): 预测概率

    返回:
        epsilon (float): 最佳阈值
        F1 (float): 最佳 F1 分数
    """
    best_epsilon = 0
    best_F1 = 0
    step_size = (max(p_val) - min(p_val)) / 1000

    for epsilon in np.arange(min(p_val), max(p_val), step_size):
        predictions = (p_val < epsilon)  # p < epsilon 时标记为异常
        tp = np.sum((predictions == 1) & (y_val == 1))
        fp = np.sum((predictions == 1) & (y_val == 0))
        fn = np.sum((predictions == 0) & (y_val == 1))

        prec = tp / (tp + fp) if (tp + fp) > 0 else 0
        rec = tp / (tp + fn) if (tp + fn) > 0 else 0
        F1 = 2 * prec * rec / (prec + rec) if (prec + rec) > 0 else 0

        if F1 > best_F1:
            best_F1 = F1
            best_epsilon = epsilon

    return best_epsilon, best_F1
```

测试：

```python
p_val = multivariate_gaussian(X_val, mu, var)
epsilon, F1 = select_threshold(y_val, p_val)
print("最佳 epsilon:", epsilon)
print("最佳 F1 分数:", F1)
# UNIT TEST
select_threshold_test(select_threshold)
```

**输出：**

```
最佳 epsilon: 8.990853e-05
最佳 F1 分数: 0.875000
```

![等高线图2](/static/images/MLc3/outputw1_31_1.png)

#### 标记异常点

使用 \(\epsilon\)，我们可以在 `X_train` 中标记异常点：

```python
outliers = p < epsilon
visualize_fit(X_train, mu, var)
plt.plot(X_train[outliers, 0], X_train[outliers, 1], 'ro',
         markersize=10, markerfacecolor='none', markeredgewidth=2)
```

红色圆圈突出了检测到的异常点——与我们的直观判断相符！

---

<a name="2.4"></a>
### 2.4 应用于高维数据

现在，让我们将算法应用于一个更复杂的数据集，该数据集包含 11 个特征，捕捉了更多服务器的属性。

#### 加载数据

```python
X_train_high, X_val_high, y_val_high = load_data_multi()
print("X_train_high 的形状:", X_train_high.shape)
```

**输出：**

```
X_train_high 的形状: (1000, 11)
```

训练集中有 1000 个样本，每个样本有 11 个特征。

#### 运行异常检测

重复前面的步骤：

1. 估计高斯参数。
2. 计算概率。
3. 选择阈值。

```python
mu_high, var_high = estimate_gaussian(X_train_high)
p_high = multivariate_gaussian(X_train_high, mu_high, var_high)
p_val_high = multivariate_gaussian(X_val_high, mu_high, var_high)
epsilon_high, F1_high = select_threshold(y_val_high, p_val_high)

print("最佳 epsilon:", epsilon_high)
print("最佳 F1 分数:", F1_high)
print("检测到的异常数量:", sum(p_high < epsilon_high))
```

**输出：**

```
最佳 epsilon: 1.377229e-18
最佳 F1 分数: 0.615385
检测到的异常数量: 117
```

虽然 \(F_1\) 分数较低（0.615），但这反映了数据复杂性的增加。尽管如此，我们仍然检测到 117 个异常——相当不错！

---

<a name="3"></a>
## 3 - 交互式可视化

为了更直观地理解高斯分布和异常检测的工作原理，我们提供了三个交互式可视化工具。

<a name="3.1"></a>
### 3.1 高斯分布与异常检测

第一个可视化展示了高斯分布的概率密度函数（PDF）以及如何通过调整参数来影响异常检测：

<IframeEmbed
  src="/static/visualizations/anomaly_detection_gaussian.html"
  minHeight={980}
  title="高斯分布与异常检测交互式可视化"
/>

**使用说明：**

- 调整 **均值 μ** 和 **标准差 σ** 来改变高斯分布的形状
- 修改 **异常阈值 ε** 来控制异常检测的敏感度
- 观察散点图中正常样本（绿色）和异常样本（红色X）的分布
- 实时统计显示检测到的异常数量和比例

<a name="3.2"></a>
### 3.2 F1分数与阈值选择

第二个可视化帮助你理解如何选择最佳阈值 ε，以及精确率、召回率和F1分数之间的权衡：

<IframeEmbed
  src="/static/visualizations/f1_score_threshold.html"
  minHeight={1020}
  title="F1分数与阈值选择"
/>

**关键洞察：**

- **精确率高**：意味着检测到的异常中，真正是异常的比例高（误报少）
- **召回率高**：意味着真实异常中，被成功检测到的比例高（漏报少）
- **F1分数**：是精确率和召回率的调和平均，帮助找到最佳平衡点
- 混淆矩阵直观展示了TP、FP、FN、TN四个指标

<a name="3.3"></a>
### 3.3 多维高斯分布3D可视化

第三个可视化展示了二维高斯分布的3D概率密度曲面和等高线图：

<IframeEmbed
  src="/static/visualizations/multivariate_gaussian_3d.html"
  minHeight={1040}
  title="多维高斯分布3D可视化"
/>

**探索要点：**

- 调整两个维度的均值和方差，观察概率密度曲面的变化
- **相关系数 ρ** 控制两个特征之间的相关性：
  - ρ = 0：特征独立，等高线呈圆形
  - ρ > 0：正相关，等高线呈椭圆形（正向倾斜）
  - ρ < 0：负相关，等高线呈椭圆形（负向倾斜）
- 3D曲面图展示了概率密度的"山峰"形状
- 等高线图（俯视图）更清晰地显示了不同概率密度的区域

---

<a name="4"></a>
## 4 - 深入理解高斯分布

<a name="4.1"></a>
### 4.1 为什么选择高斯分布？

高斯分布（正态分布）在异常检测中如此流行，有以下几个原因：

**1. 中心极限定理**

根据中心极限定理，大量独立随机变量的和趋向于正态分布。这意味着许多自然现象和测量数据都近似服从正态分布。

**2. 数学性质优良**

- 只需两个参数（均值 μ 和方差 σ²）就能完全描述
- 具有良好的数学性质，易于计算和优化
- 加法封闭性：两个高斯分布的和仍是高斯分布

**3. 最大熵原理**

在给定均值和方差的约束下，高斯分布是熵最大的分布，这意味着它做出了最少的假设。

<a name="4.2"></a>
### 4.2 单变量 vs 多变量高斯分布

**单变量高斯分布**

对于单个特征，概率密度函数为：

$$p(x ; \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\frac{(x - \mu)^2}{2 \sigma^2} \right)$$

**多变量高斯分布**

对于 n 维特征向量 $\mathbf{x} = [x_1, x_2, ..., x_n]^T$，概率密度函数为：

$$p(\mathbf{x} ; \boldsymbol{\mu}, \boldsymbol{\Sigma}) = \frac{1}{(2\pi)^{n/2} |\boldsymbol{\Sigma}|^{1/2}} \exp \left( -\frac{1}{2} (\mathbf{x} - \boldsymbol{\mu})^T \boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu}) \right)$$

其中：

- $\boldsymbol{\mu}$ 是均值向量
- $\boldsymbol{\Sigma}$ 是协方差矩阵
- $|\boldsymbol{\Sigma}|$ 是协方差矩阵的行列式

**何时使用多变量高斯分布？**

在我们的实现中，我们假设特征之间是独立的，因此：

$$p(\mathbf{x}) = p(x_1; \mu_1, \sigma_1^2) \times p(x_2; \mu_2, \sigma_2^2) \times ... \times p(x_n; \mu_n, \sigma_n^2)$$

这种方法计算效率高，但如果特征之间存在相关性，使用完整的多变量高斯分布（考虑协方差矩阵）会更准确。

<a name="4.3"></a>
### 4.3 协方差矩阵的作用

协方差矩阵 $\boldsymbol{\Sigma}$ 捕捉了特征之间的相关性：

$$
\boldsymbol{\Sigma} = \begin{bmatrix}
\sigma_1^2 & \sigma_{12} & \cdots & \sigma_{1n} \\
\sigma_{21} & \sigma_2^2 & \cdots & \sigma_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
\sigma_{n1} & \sigma_{n2} & \cdots & \sigma_n^2
\end{bmatrix}
$$

- **对角线元素** $\sigma_i^2$：第 i 个特征的方差
- **非对角线元素** $\sigma_{ij}$：特征 i 和 j 之间的协方差

**实现多变量高斯分布：**

```python
def multivariate_gaussian_full(X, mu, Sigma):
    """
    完整的多变量高斯分布实现（考虑协方差）

    参数:
        X (ndarray): (m, n) 数据矩阵
        mu (ndarray): (n,) 均值向量
        Sigma (ndarray): (n, n) 协方差矩阵

    返回:
        p (ndarray): (m,) 每个样本的概率密度
    """
    n = len(mu)

    # 计算协方差矩阵的行列式和逆矩阵
    det_Sigma = np.linalg.det(Sigma)
    inv_Sigma = np.linalg.inv(Sigma)

    # 标准化系数
    coefficient = 1 / ((2 * np.pi) ** (n / 2) * np.sqrt(det_Sigma))

    # 计算马氏距离
    X_centered = X - mu
    exponent = -0.5 * np.sum(X_centered @ inv_Sigma * X_centered, axis=1)

    return coefficient * np.exp(exponent)
```

---

<a name="5"></a>
## 5 - 实战技巧与常见问题

<a name="5.1"></a>
### 5.1 如何选择特征？

**好的特征应该满足：**

1. **近似高斯分布**：如果特征不服从高斯分布，可以尝试变换：
   - 对数变换：$x \rightarrow \log(x + c)$
   - 平方根变换：$x \rightarrow \sqrt{x}$
   - 幂变换：$x \rightarrow x^{1/n}$

2. **对异常敏感**：选择那些在异常情况下会显著变化的特征

3. **相对独立**：如果特征高度相关，考虑使用主成分分析（PCA）降维

**特征工程示例：**

```python
import matplotlib.pyplot as plt

# 检查特征分布
def check_distribution(X, feature_names):
    """可视化特征分布，检查是否近似高斯分布"""
    n_features = X.shape[1]
    fig, axes = plt.subplots(1, n_features, figsize=(5*n_features, 4))

    for i in range(n_features):
        axes[i].hist(X[:, i], bins=50, edgecolor='black', alpha=0.7)
        axes[i].set_title(f'{feature_names[i]} 分布')
        axes[i].set_xlabel('值')
        axes[i].set_ylabel('频数')

    plt.tight_layout()
    plt.show()

# 对数变换示例
def log_transform(X, epsilon=1e-10):
    """对偏斜分布应用对数变换"""
    return np.log(X + epsilon)

# 使用示例
check_distribution(X_train, ['吞吐量', '延迟'])

# 如果分布偏斜，应用变换
X_train_transformed = log_transform(X_train)
check_distribution(X_train_transformed, ['log(吞吐量)', 'log(延迟)'])
```

<a name="5.2"></a>
### 5.2 处理不平衡数据

在异常检测中，异常样本通常远少于正常样本。这会导致：

**问题：**

- 模型可能过度拟合正常样本
- F1分数可能不够敏感

**解决方案：**

1. **使用合适的评估指标**：
   - 不要只看准确率（Accuracy），因为即使将所有样本都预测为正常，准确率也可能很高
   - 使用 F1 分数、精确率-召回率曲线（PR Curve）或 ROC-AUC

2. **调整阈值**：
   - 根据业务需求调整 ε
   - 如果漏报代价高（如医疗诊断），降低 ε 提高召回率
   - 如果误报代价高（如垃圾邮件过滤），提高 ε 提高精确率

3. **采样技术**（如果有标签数据）：
   - 过采样异常样本（SMOTE）
   - 欠采样正常样本

<a name="5.3"></a>
### 5.3 模型验证与调试

**调试检查清单：**

```python
def validate_anomaly_detector(X_train, X_val, y_val, mu, var, epsilon):
    """
    验证异常检测模型的性能
    """
    print("=" * 50)
    print("异常检测模型验证报告")
    print("=" * 50)

    # 1. 检查训练数据
    print(f"\n1. 训练数据统计:")
    print(f"   样本数: {X_train.shape[0]}")
    print(f"   特征数: {X_train.shape[1]}")
    print(f"   均值: {mu}")
    print(f"   方差: {var}")

    # 2. 检查验证数据
    print(f"\n2. 验证数据统计:")
    print(f"   样本数: {X_val.shape[0]}")
    print(f"   异常样本数: {np.sum(y_val == 1)}")
    print(f"   异常比例: {np.sum(y_val == 1) / len(y_val) * 100:.2f}%")

    # 3. 计算概率分布
    p_train = multivariate_gaussian(X_train, mu, var)
    p_val = multivariate_gaussian(X_val, mu, var)

    print(f"\n3. 概率分布:")
    print(f"   训练集概率范围: [{np.min(p_train):.2e}, {np.max(p_train):.2e}]")
    print(f"   验证集概率范围: [{np.min(p_val):.2e}, {np.max(p_val):.2e}]")
    print(f"   选择的阈值 ε: {epsilon:.2e}")

    # 4. 性能指标
    predictions = (p_val < epsilon)
    tp = np.sum((predictions == 1) & (y_val == 1))
    fp = np.sum((predictions == 1) & (y_val == 0))
    fn = np.sum((predictions == 0) & (y_val == 1))
    tn = np.sum((predictions == 0) & (y_val == 0))

    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

    print(f"\n4. 性能指标:")
    print(f"   精确率: {precision:.4f}")
    print(f"   召回率: {recall:.4f}")
    print(f"   F1分数: {f1:.4f}")
    print(f"   混淆矩阵:")
    print(f"   ┌─────────────┬──────────┬──────────┐")
    print(f"   │             │ 预测正常 │ 预测异常 │")
    print(f"   ├─────────────┼──────────┼──────────┤")
    print(f"   │ 实际正常    │ {tn:8d} │ {fp:8d} │")
    print(f"   │ 实际异常    │ {fn:8d} │ {tp:8d} │")
    print(f"   └─────────────┴──────────┴──────────┘")

    # 5. 异常检测结果
    train_anomalies = np.sum(p_train < epsilon)
    print(f"\n5. 检测结果:")
    print(f"   训练集中检测到的异常: {train_anomalies} ({train_anomalies/len(p_train)*100:.2f}%)")
    print(f"   验证集中检测到的异常: {np.sum(predictions)} ({np.sum(predictions)/len(predictions)*100:.2f}%)")

    print("=" * 50)

# 使用示例
validate_anomaly_detector(X_train, X_val, y_val, mu, var, epsilon)
```

<a name="5.4"></a>
### 5.4 性能优化

对于大规模数据集，计算效率很重要：

**1. 向量化计算**

```python
# 慢速版本（使用循环）
def estimate_gaussian_slow(X):
    m, n = X.shape
    mu = np.zeros(n)
    var = np.zeros(n)

    for j in range(n):
        mu[j] = np.sum(X[:, j]) / m
        var[j] = np.sum((X[:, j] - mu[j]) ** 2) / m

    return mu, var

# 快速版本（向量化）
def estimate_gaussian_fast(X):
    mu = np.mean(X, axis=0)
    var = np.var(X, axis=0)
    return mu, var

# 性能对比
import time

X_large = np.random.randn(10000, 100)

start = time.time()
mu1, var1 = estimate_gaussian_slow(X_large)
time_slow = time.time() - start

start = time.time()
mu2, var2 = estimate_gaussian_fast(X_large)
time_fast = time.time() - start

print(f"慢速版本: {time_slow:.4f}秒")
print(f"快速版本: {time_fast:.4f}秒")
print(f"加速比: {time_slow/time_fast:.2f}x")
```

**2. 批处理**

对于超大数据集，可以分批处理：

```python
def estimate_gaussian_batch(X, batch_size=1000):
    """分批估计高斯参数，节省内存"""
    n = X.shape[1]
    mu = np.zeros(n)
    var = np.zeros(n)
    m = X.shape[0]

    # 计算均值
    for i in range(0, m, batch_size):
        batch = X[i:i+batch_size]
        mu += np.sum(batch, axis=0)
    mu /= m

    # 计算方差
    for i in range(0, m, batch_size):
        batch = X[i:i+batch_size]
        var += np.sum((batch - mu) ** 2, axis=0)
    var /= m

    return mu, var
```

<a name="5.5"></a>
### 5.5 扩展到其他异常检测方法

高斯分布模型是异常检测的基础，但还有其他强大的方法：

**1. 基于密度的方法**

- **LOF (Local Outlier Factor)**：基于局部密度的异常检测
- **DBSCAN**：基于密度的聚类，可以识别噪声点

**2. 基于距离的方法**

- **K-近邻 (KNN)**：计算样本到其K个最近邻的平均距离
- **孤立森林 (Isolation Forest)**：通过随机分割快速隔离异常点

**3. 基于重构的方法**

- **自编码器 (Autoencoder)**：神经网络学习数据的压缩表示，重构误差大的样本为异常
- **PCA**：主成分分析，投影误差大的样本为异常

**简单的孤立森林示例：**

```python
from sklearn.ensemble import IsolationForest

# 训练孤立森林
iso_forest = IsolationForest(contamination=0.1, random_state=42)
iso_forest.fit(X_train)

# 预测异常（-1表示异常，1表示正常）
predictions = iso_forest.predict(X_val)
anomalies = (predictions == -1)

print(f"检测到的异常数量: {np.sum(anomalies)}")
```

---

<a name="summary"></a>
## 总结

恭喜你完成了这场异常检测的学习之旅！通过这篇博客，你已经：

- 使用高斯分布构建了异常检测算法。
- 学会了估计 $\mu$ 和 $\sigma^2$，通过 $F_1$ 分数选择 $\epsilon$，并可视化结果。
- 将其应用于二维和高维数据集。
- 深入理解了高斯分布的数学原理和协方差矩阵的作用。
- 掌握了特征工程、模型验证和性能优化的实战技巧。
- 了解了其他异常检测方法的扩展方向。

这项技能在监控系统、检测欺诈或识别任何数据中的异常值时都非常有用。

---

希望这篇文章帮助你深入理解了异常检测的核心原理与实践方法！想进一步探索？试试调整不同的阈值 ε 和高斯参数，观察检测效果的变化。

完整代码已开源在[GitHub仓库](https://github.com/kkkano/machine-learning-notebook/blob/main/C3/W1_Anomaly_Detection.ipynb)

**本篇文章的部分内容和思想参考了 [吴恩达 (Andrew Ng)](https://www.andrewng.org/) 在 [Coursera 机器学习课程](https://www.coursera.org/learn/machine-learning) 中的讲解，感谢他对机器学习领域的卓越贡献。**
