---
title: 'LLM 在编程领域的局限性'
date: '2025-02-09'
tags: ['LLM', 'coding agent', 'context window', 'reasoning vs. coding']
draft: false
comments: true
summary: '探讨 LLM 和当前 Agent 技术在编程方面的局限性'
authors: ['allen']
---

_Source_:https://x.com/lidangzzz/status/1871505849983594677?t=5UnA5rIonz0gelZk-LMAjQ&s=05
_Author_::[lidangzzz](https://x.com/lidangzzz)

## Introduction

This post explores the limitations of LLMs and current Agent technology in programming, emphasizing the differences between real - world coding and solving TCS problems, and highlighting the importance of expanding the context window.

<TOCInline toc={props.toc} exclude="Introduction" />

## The original

很多人说，reasoning=coding，o3就是最能写代码的模型。  

我的看法是，reasoning指的是扔一个简单干净的问题，给出天才回答的能力。  

这么说吧，如果把o3扔到20世纪，一定是全世界最牛逼的理论CS科学家，3-SAT、max flow、min cut、红黑树、LU分解、KMP、各种proof-base的加密算法，轻轻松松全拿下， 一口气构建整个TCS大厦。  

解决TCS问题，就是解决抽象出来的数学、计算、拓扑问题，本质上可以认为和“解决数学难题”是一种类似的能力。  

（但是解决CS问题不等于解决数学问题，我始终跟大家科普，cs不等于数学，cs和pure math没有直接关系）  

但是，真正日常工作上班写代码，跟研究理论计算机问题，是完完全全的两种能力、两种模式、两种思维。  

现实中真正的coding能力，不仅是把系统搭好，而且需要强烈的耐压能力和记忆力，还要不断动手配置、动手测试、动手调试、完成各种profiling的工作，  

你不止需要跳跃式读代码，和机器互动，你还要跟同事互动，跟一大堆文档互动，跟不同配置环境互动，跟各种dependency的文档互动，然后把这些复杂的关系一一捋清楚，记在脑子里，然后一点点去把模块和功能摸索一遍。  

这跟设计一个简单、干净、天才、杰出的TCS算法，是完完全全的两回事。  

另外，你也千万不要认为architect（架构师）是在解决高级、抽象、干净、完美的数学题，  

真正合格的architect，恰恰是手最脏、摸技术细节最多、调试最多、profiling最多的人——然后从这些反复枯燥的工作中，不断总结和思考，不断用脏手去尝试，做出正确架构和设计的选择，  

说“真正的架构师，才需要o3级别的智能”的人，都是纯纯的大外行。  

现在所有做coding agent的项目，都遇到一个最直接的死穴：context window太小了，几个文件还能喂进去，整个代码是不可能喂进去的。  

现在一堆人在专注于给agent解决memory的问题，但是在针对coding问题上，用memory是不能解决任何问题的。  

现在市场上的coding agent大概就是这么一个水平的人：  

你给他看一个定义充足、干净、简单、难度高的问题，他可以通过step by step的reasoning，给你一个非常精美的解；  

你给他一个20万行代码的巨型project，根本没办法下手；  

然后coding agent的作者们，会用各种RAG的方法，去给model去喂一堆各种片段，试图用few shot的办法来直接幻想出答案——结果必然是错的（比如cursor、windsurf），  

而另一些coding agent的作者们，试图step by step引导gpt-4o，去完成design driven或者test driven的开发流程，用大量的资源去保证每一步提供gpt-4o的信息量是充足的，以等待他进行下一步的action，包括添加文件、修改文件，或者在terminal里执行运行、编译、测试等等工作（比如devin），  

而更麻烦的问题是，现实中绝大多数人还要跟aws打交道，跟database打交道，跟各种private key和权限打交道，跟各种container打交道——本质就是跟不同的环境和人打交道，  

而这种coding以外的工作，要么交给一个human proxy，在适当的时刻引导人类去干预指导（非常复杂且需要实时盯着），要么你开始把所有密码、账户、权限都交给它，让它来决定什么时候去操作（非常危险），  

总而言之，我反复讲的一点：  

LLM和目前Agent技术，可以代替很多tcs（理论计算机） phd，  

但是代替不了业务和工作稍微复杂一点点的程序员，包括设计复杂system（包括mlsys）的phd。  

所以这也是我为什么从最最一开始就看好moonshot，其实context window在一些诸如coding或者法律工作中上限的能力，  

如果你相信scaling law，你就应该不仅相信multi agent，parallel task scheduling，也应该相信context window的问题会逐步解决，  

如果不把context window解决掉，或者坚信fine tuning比context window更重要——那么很多问题就会彻底卡死，成为这一轮AI、LLM、vertical AI agent浪潮的真正瓶颈。
							
<sub>本文转载自[lidangzzz](https://x.com/lidangzzz)</sub>

## 立党老师观点:

- **理论问题解决能力强**：AI 大模型像 GPT - 4 在解决理论计算机问题上很厉害，像设计算法、数学证明这类抽象干净的问题能轻松搞定，就像天才科学家。
- **实际编程能力差**：但在实际写代码干工程活时完全不行，因为工作中要面对屎山代码、调试、配环境、读文档、和同事扯皮等复杂情况，模型根本玩不转。
- **当前问题**：AI 写代码的工具如 Devin、Cursor 最大的问题是 “记性太差”，代码量一多就处理不了，强行用技巧拼凑结果也容易出错。
- **未来关键**：要想突破就得解决 “记性”（context window）问题，否则 AI 写代码永远只能搞小作业，干不了正经项目。

## 我的看法:

- **理论vs实践**：同意立党观点。模型能解数学题，但工程是脏活累活，需要和人、系统、细节打交道，目前AI确实不擅长。
- **context window是命门**：现在模型记性差（比如只能看几页代码），导致它像“金鱼脑”，稍微复杂点的项目就蒙圈。扩展上下文确实是刚需，但成本和技术挑战也大。
- **AI写代码的定位**：短期更适合辅助工具（比如生成代码片段、修bug），但想替代程序员？除非能真正“理解”业务逻辑和团队协作——这比解3-SAT难多了。
- **安全问题**：把AWS密钥、数据库权限交给AI操作？想想就害怕……

~~（个人吐槽：现在的AI写代码工具，就像学霸帮你写作业，但真让他去公司996，分分钟被开除😂）~~
## 扩展讨论

### 为什么LLM在理论问题上表现出色？

LLM（如GPT-4）在理论计算机科学（TCS）问题上表现优异，因为这些问题通常是抽象、干净且定义明确的。例如，设计一个新算法或证明一个数学定理，LLM可以通过强大的模式识别和逻辑推理能力快速生成解决方案。这种能力类似于一个天才科学家，能够在短时间内解决复杂的数学或计算难题。

### 实际编程中的挑战

然而，实际编程远比理论问题复杂得多。程序员需要处理遗留代码（俗称“屎山”）、配置开发环境、调试错误、与团队协作、阅读冗长文档等。这些任务需要耐压能力、对细节的敏感以及强大的记忆力，而LLM在这方面明显不足，因为它们缺乏对复杂系统和人际互动的真正理解。

### 上下文窗口的限制

上下文窗口（context window）是LLM面临的核心限制。目前的模型只能处理有限的token数量，例如几千到几万不等，这意味着它们无法一次性理解一个大型代码库（比如20万行代码）。这就像试图通过只读一本书的前几页来理解整个故事，必然会导致信息缺失和误解。虽然一些技术（如RAG，检索增强生成）试图通过分段喂入信息来缓解这一问题，但结果往往不理想，尤其是在需要整体上下文的项目中。

### 安全与协作问题

现实编程中，程序员经常需要与外部系统交互，例如AWS云服务、数据库、私钥权限管理、容器技术等。将这些敏感操作交给AI存在重大安全隐患，比如数据泄露或服务中断。此外，AI缺乏社交能力和适应性，无法有效参与团队协作或处理突发的人际问题，这进一步限制了其在实际开发中的应用。

### 未来展望

要让LLM在编程领域更进一步，扩展上下文窗口是关键，这可能需要硬件和算法的双重突破。同时，开发更智能的信息管理技术（例如长期记忆机制）以及确保AI在开发流程中的安全集成也至关重要。尽管当前存在诸多挑战，AI仍可用于自动化重复性任务（如代码补全或测试用例生成），未来有望更深入融入软件开发生命周期。

### 个人体验与建议

从我个人的使用经验来看，AI编码助手在小型、定义明确的任务上表现不错，比如生成代码片段或修复简单bug。但在处理大型项目时，它们经常因为缺乏对整体系统的理解而引入错误。因此，我建议将AI作为辅助工具，用于加速开发中的特定环节，而不是指望它独立管理整个项目。

### 讨论与反馈

你对AI在编程中的应用有什么看法？它在你的工作中帮上忙了吗？欢迎在评论区分享你的体验和建议！


